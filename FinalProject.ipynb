{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members: \n",
    "- A14178715\n",
    "- A11475687\n",
    "- A12594395\n",
    "- A11729103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and Background:\n",
    "\n",
    "What would it look like if we visualized a predicted sea level rise for the future? How accurate can we get based on a large dataset of the sea level rising over a long period of time?\n",
    "\n",
    "Well, we should see a fairly accurate model of future sea level, represented by a map of the coastal regions of California flooded. This model will get less and less accurate the further we go into the future. To start, we need data. Here is a good one:\n",
    "\n",
    "ftp://podaac.jpl.nasa.gov/allData/merged_alt/L2/TP_J1_OSTM/global_mean_sea_level/GMSL_TPJAOS_V4_199209_201702.txt\n",
    "\n",
    "This is NASA's data on calculating the sea level increase with satellites. The link worked a while back, but no longer works, so we downloaded the data while it was available and have included it in our repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description:\n",
    "\n",
    "NASA's description of the data:\n",
    "\n",
    "\"Global Mean Sea Level Data\"\n",
    "This file contains Global Mean Sea Level (GMSL) variations computed at the NASA Goddard Space Flight Center under the \n",
    "auspices of the NASA MEaSUREs program. The GMSL was generated using the Integrated Multi-Mission Ocean Altimeter Data for Climate Research (http://podaac.jpl.nasa.gov/dataset/MERGED_TP_J1_OSTM_OST_ALL_V4). It combines Sea Surface Heights from TOPEX/Poseidon, Jason-1, OSTM/Jason-2, and Jason-3 to a common terrestrial reference frame with all inter-mission biases, range and geophysical corrections applied and placed onto a georeferenced orbit. This creates a consistent data record throughout time, regardless of the instrument used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "txtFile = \"nasa_data_noheader.txt\"\n",
    "csvFile = \"data.csv\"\n",
    "def processTxt(txtFile):\n",
    "    with open(txtFile,'r') as in_file:\n",
    "        #Our lines in nasa data have 1-4 spaces of separation so first we split the line\n",
    "        stripped = (line.strip() for line in in_file)\n",
    "        lines = (line.split(\" \") for line in stripped if line)\n",
    "        \n",
    "        #Then here we write it to the csv and if there is an empty space it will replace it with nothing \n",
    "        with open(csvFile,'w') as out_file:\n",
    "            #Column titles (adds empty row 2 we can just delete once its in pandas dataframe)\n",
    "            writer = csv.writer(out_file)\n",
    "            writer.writerow(('col1','col2','col3','col4','col5','col6','col7','col8','col9','col10','col11','col12'))\n",
    "            for line in lines:\n",
    "                for index in line:\n",
    "                    #Replacing the white space with nothing\n",
    "                    index.replace(\" \", \"\") \n",
    "                    if index != \"\":\n",
    "                        out_file.write(index + \",\")\n",
    "                out_file.write('\\n')\n",
    "processTxt(txtFile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "#remove the extra row (row2), drops only if all col = nan\n",
    "df = df.dropna(how = 'all')\n",
    "\n",
    "#hardcode way\n",
    "#df = df.drop(df.index[1])\n",
    "\n",
    "\n",
    "#drop the columns we don't need\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot data using plt.something()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict future sea level rise for the next 100 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show what this prediction looks like in a google map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusions and Discussion:\n",
    "\n",
    "the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
